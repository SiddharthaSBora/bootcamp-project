{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Insurance Erdos Data Camp Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package and data\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the data \n",
    "df = pd.read_csv('../0-data/Root_Insurance_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the correlation\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descriptive information about variables by rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## summary statistics of all other variables based on Rank  \n",
    "df.groupby(['rank']).agg(\n",
    "{'Currently Insured':\"count\",\n",
    " 'Number of Vehicles':[min,max,sum],\n",
    " 'Number of Drivers':[min,max,sum],\n",
    " 'Marital Status':\"count\",\n",
    " 'click':\"count\",\n",
    " 'policies_sold':\"sum\"\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## summary statistics of all other variables based on Rank and Click \n",
    "df.groupby(['rank','click']).agg(\n",
    "{'click':\"sum\",\n",
    " 'Currently Insured':\"count\",\n",
    " 'Number of Vehicles':[min,max,sum],\n",
    " 'Number of Drivers':[min,max,sum],\n",
    " 'Marital Status':\"count\",\n",
    " 'policies_sold':\"sum\"\n",
    "}\n",
    ")\n",
    "\n",
    "# any thoughts here? feel free to add yours \n",
    "# company can sell the policy only if the ad is clicked \n",
    "# increase the rank based on attributes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate click-through-rate (CTR)\n",
    "### It is the ratio of sum of the number of clicks over the number of total observations.\n",
    "ctr = df.click.value_counts(\"True\")\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the package\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data clean\n",
    "## Currently Insured: categorical/unknow, N, Y\n",
    "## Number of Vehicles: ordinal\n",
    "## Number of Drivers: ordinal\n",
    "## Marital Status: categorical/ M, S\n",
    "## rank: ordinal\n",
    "\n",
    "## There are two ways to run regressions when having categorial variables in datasets.\n",
    "## 1. Delete those categorical variables.\n",
    "## 2. Keep them but generate dummy variables. \n",
    "## since we don't have much features in our dataset, i would go for dummies.\n",
    "\n",
    "## Create dummies for Currently Insured and Marital Status. \n",
    "## 1. For Currently Insured, i left \"unknow\" as baseline case. So Insured_N, and Insured_Y are created and included. \n",
    "## 2. For Marital Status, i left \"S\" as baseline case. So Married are created and included. \n",
    "## For the other variables I would treat them as ordinal.\n",
    "\n",
    "pd.get_dummies(df['Currently Insured'])\n",
    "df['Insured_N'] = pd.get_dummies(df['Currently Insured'])['N']\n",
    "df['Insured_Y'] = pd.get_dummies(df['Currently Insured'])['Y']\n",
    "\n",
    "pd.get_dummies(df['Marital Status'])\n",
    "df['Married'] = pd.get_dummies(df['Marital Status'])['M']\n",
    "\n",
    "pd.get_dummies(df['click'])\n",
    "df['click_true'] = pd.get_dummies(df['click'])[True]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. click "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 click without interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define X and Y\n",
    "\n",
    "X = df[['Insured_N', 'Insured_Y', 'Number of Vehicles', 'Number of Drivers', 'Married','rank']].copy()\n",
    "X = sm.add_constant(X)\n",
    "y = df['click_true'].copy()\n",
    "\n",
    "## define and fit the model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit(method='newton')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## result summary\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 click with interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. policies_sold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. policies_sold without interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.2 the outcome variable is \"policies_sold\"\n",
    "y = df['policies_sold'].copy()\n",
    "\n",
    "## define and fit the model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit(method='newton')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['policies_sold'].copy()\n",
    "\n",
    "## define and fit the model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit(method='newton'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 policies_sold with interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1 Logistic regression\n",
    "## import the package \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "## Precision\n",
    "from sklearn.metrics import precision_score\n",
    "## Recall\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train-test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,\n",
    "                                                test_size=.2,\n",
    "                                                shuffle=True,\n",
    "                                                random_state=614,\n",
    "                                                stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit the model by using train dataset\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(y_pred,y_actual):\n",
    "    return np.sum(y_pred == y_actual)/len(y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validation\n",
    "kfold = StratifiedKFold(5,shuffle=True,random_state=440)\n",
    "\n",
    "\n",
    "## cut-offs \n",
    "cutoffs = np.arange(0,1,.01)\n",
    "\n",
    "accs = np.zeros((5,len(cutoffs)))\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train_index,test_index in kfold.split(X_train,y_train):\n",
    "    X_train_train,X_train_test = X_train.iloc[train_index],X_train.iloc[test_index]\n",
    "    y_train_train,y_train_test = y_train.iloc[train_index],y_train.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    for j in range(len(cutoffs)):\n",
    "        log_reg_clone = clone(log_reg)\n",
    "        log_reg_clone.fit(X_train_train,y_train_train)\n",
    "        probs = log_reg_clone.predict_proba(X_train_test)[:,1]\n",
    "        \n",
    "        y_pred = 1*(probs > cutoffs[j])\n",
    "        accs[i,j] = get_acc(y_pred,y_train_test)\n",
    "        \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the figure\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "\n",
    "plt.plot(cutoffs,np.mean(accs,axis=0))\n",
    "\n",
    "plt.xlabel(\"Cutoff\", fontsize=16)\n",
    "plt.ylabel(\"Mean CV Accuracy\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The cutoff with highest mean CV accuracy was\",\n",
    "         cutoffs[np.argmax(np.mean(accs,axis=0))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "b026a24107c4fa174511a0e9ec01fca6bc879b7956827bc1964472816114dd20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
